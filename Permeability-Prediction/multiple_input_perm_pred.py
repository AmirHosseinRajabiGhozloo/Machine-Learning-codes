# -*- coding: utf-8 -*-
"""Multiple-Input-Perm-Pred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rZKzjb__Vsbchh_rO6mKZgQqk7dVdhkH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import (concatenate,Conv2D,Conv1D,MaxPool2D,add,Input,Dense,Flatten,
                                     BatchNormalization,Activation)
from tensorflow.keras.models import Model,Sequential
from tensorflow.keras.optimizers import (RMSprop,Adam,Nadam)
from tensorflow.keras.activations import relu
from tensorflow.keras.callbacks import EarlyStopping as ES
from tensorflow_addons.optimizers import (RectifiedAdam,Lookahead)
from tensorflow.keras.callbacks import LearningRateScheduler
from sklearn.model_selection import train_test_split as tts
from sklearn.metrics import mean_squared_error as MSE
import cv2
from tlbo import Student,tlbo
from tqdm import tqdm
from scipy.io import savemat
import levenberg_marquardt as lm

def R2 (true,predicted):
    import numpy as np
    R2 = np.mean((predicted-predicted.mean())*(true-true.mean()))/(np.std(predicted)*np.std(true))
    return R2
def R(true,predicted):
    R = (np.sum((true-true.mean())*(predicted-predicted.mean())))/(np.sqrt((np.sum((true-true.mean())**2))*np.sum((true-true.mean())**2)))
    return R

df = pd.read_excel("D:/hassan sharifi/milad's project/img/data.xlsx")
orig_df = df.copy()
df

# new data = train+test+blind
df = pd.read_excel("D:/hassan sharifi/milad's project/new_data.xlsx")
orig_df = df.copy()
df

# new data = train+test+blind
df = pd.read_excel("D:/hassan sharifi/milad's project/new_data_2.xlsx")
orig_df = df.copy()
df

target = df.pop('log(NMR_PERM)').values
index = df.pop('index')
features = df
del df
features

Features = features.values.reshape(features.shape[0],features.shape[1],1)
target = target.reshape(-1,1)

def float_to_bin(arr, places = 32):
    import matplotlib.pyplot as plt
    bin_list = []
    for number in arr:
        whole, dec = str(number).split(".")
        whole = int(whole)
        dec = int (dec)
        res = bin(whole).lstrip("0b") + "."
        for x in range(places):
            whole, dec = str((decimal_converter(dec)) * 2).split(".")
            dec = int(dec)
            res += whole
        res = res.split('.')[1]
        res = [float(i) for i in res]
        bin_list.append(res)
        #fig = plt.imshow(bin_list,cmap='gray');
    fig=1
    return [bin_list,fig]
def decimal_converter(num):
    while num > 1:
        num /= 10
    return num

# all data
bin_list = []
fig_list = []
with tqdm(total=len(features.values), desc="Progress", bar_format="{l_bar}{bar} [ time left: {remaining} ]") as pbar:
    for i in features.values:
        bin_num,fig = float_to_bin(i,32)
        bin_list.append(bin_num)
        fig_list.append(fig)
        pbar.update(1)
feature = np.array(bin_list)
feature = np.array([i.reshape(i.shape[0],i.shape[1],1) for i in feature])
print('No. of Samples:',len(feature))
print('Sample Shape:',feature[0].shape)
# Data Visualization
plt.imshow(feature[0]);
orig_df['feature binary string'] = [i for i in feature]
del bin_list
orig_df

# to save data img
'''
with tqdm(total=len(img_list), desc="Progress", bar_format="{l_bar}{bar} [ time left: {remaining} ]") as pbar:
    index = 0
    for i in img_list[index:]:
        fig = plt.imshow(i,cmap='gray')
        fig.axes.get_xaxis().set_visible(False)
        fig.axes.get_yaxis().set_visible(False)
        plt.savefig("D:/hassan sharifi/milad's project/img_resize/sample_"+str(index)+'.png',transparent=True)
        index+=1
        pbar.update(1)
'''

shape = feature[0].shape
xtr_img,xts_img,xtr_axi,xts_axi,ytr,yts = tts(feature,features,target,train_size=0.7,random_state=1,shuffle=True)
print('xtr_img shape:',xtr_img.shape)
print('xts_img shape:',xts_img.shape)
print('xtr_axi shape:',xtr_axi.shape)
print('xts_axi shape:',xts_axi.shape)
print('ytr shape:',ytr.shape)
print('yts shape:',yts.shape)

# 1
inputs = Input(shape= shape)
###################
X_1_1 = Conv2D(16,(1,1), activation="relu",padding='same')(inputs)
X_1_2 = Conv2D(64,(1,1), activation="relu",padding='same')(X_1_1)
X_1_3 = Conv2D(16,(3,3), activation="relu",padding='same')(X_1_2)
#X_1 = Conv2D(64,(3,3), activation="relu",padding='same')(inputs)
###################
X_2_1 = Conv2D(16,(1,1), activation="relu",padding='same')(X_1_3)
X_2_2 = Conv2D(64,(1,1), activation="relu",padding='same')(X_2_1)
X_2_3 = Conv2D(16,(3,3), activation="relu",padding='same')(X_2_2)
#X_2 = Conv2D(64,(3,3), activation="relu",padding='same')(X_1)
###################
X_3_1 = Conv2D(16,(1,1), activation="relu",padding='same')(X_2_3)
X_3_2 = Conv2D(64,(1,1), activation="relu",padding='same')(X_3_1)
X_3_3 = Conv2D(16,(3,3), activation="relu",padding='same')(X_3_2)
#X_3 = Conv2D(64,(3,3), activation="relu",padding='same')(X_2)
###################
'''
X_4_1 = Conv2D(16,(1,1), activation="relu",padding='same')(X_3_3)
X_4_2 = Conv2D(64,(1,1), activation="relu",padding='same')(X_4_1)
X_4_3 = Conv2D(16,(3,3), activation="relu",padding='same')(X_4_2)
#X_4 = Conv2D(64,(3,3), activation="relu",padding='same')(X_1)
'''
###################
C_1 = add([X_1_3, X_3_3])
#C_1 = add([X_3, X_4])
###################
X_5_1 = Conv2D(32,(1,1), activation="relu",padding='same')(C_1)
X_5_2 = Conv2D(128,(1,1), activation="relu",padding='same')(X_5_1)
X_5_3 = Conv2D(32,(3,3), activation="relu",padding='same')(X_5_2)
#X_5 = Conv2D(128,(3,3), activation="relu")(C_1)
mx_pool = MaxPool2D((2,2))(X_5_3)
###################
fltn = Flatten()(mx_pool)
D_1 = Dense(20,activation='relu')(fltn)

outputs = Dense(1)(D_1)
model = Model(inputs, outputs)

# 2
inputs = Input(shape= shape)
###################
X_1_1 = Conv2D(16,(1,1), activation="relu",padding='valid')(inputs)
X_1_2 = Conv2D(64,(1,1), activation="relu",padding='valid')(X_1_1)
X_1_3 = Conv2D(16,(3,3), activation="relu",padding='valid')(X_1_2)
###################
mx_pool = MaxPool2D((2,2))(X_1_3)
fltn = Flatten()(mx_pool)
D_1 = Dense(20,activation='relu')(fltn)

outputs = Dense(1)(D_1)
model = Model(inputs, outputs)
model = lm.ModelWrapper(tf.keras.models.clone_model(model))
model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),
    loss=lm.MeanSquaredError())

# 3
inputs = Input(shape= shape)
###################
X_1_1 = Conv2D(16,(1,1), activation="relu",padding='same')(inputs)
X_1_2 = Conv2D(64,(1,1), activation="relu",padding='same')(X_1_1)
X_1_3 = Conv2D(16,(3,3), activation="relu",padding='same')(X_1_2)
###################
conc = add([X_1_1,X_1_3])
###################
mx_pool = MaxPool2D((2,2))(conc)
fltn = Flatten()(mx_pool)
D_1 = Dense(20,activation='relu')(fltn)

outputs = Dense(1)(D_1)
model = Model(inputs, outputs)

# 4
inputs = Input(shape= shape)
###################
X_1 = Conv2D(16,(1,1),padding='valid')(inputs)
ac_1 = Activation('relu')(X_1)
bt_1 = BatchNormalization()(ac_1)
X_2 = Conv2D(64,(1,1), padding='valid')(bt_1)
ac_2 = Activation('relu')(X_2)
bt_2 = BatchNormalization()(ac_2)
X_3 = Conv2D(16,(3,3),padding='valid')(bt_2)
ac_3 = Activation('relu')(X_3)
bt_3 = BatchNormalization()(ac_3)
###################
fltn = Flatten()(bt_3)
D_1 = Dense(20,activation='relu')(fltn)

outputs = Dense(1)(D_1)
model = Model(inputs, outputs)

# 5
inputs = Input(shape= (7, 32, 1))
X_1 = Conv2D(16,(3,3),padding='same')(inputs)
btn_1 = BatchNormalization()(X_1)
act_1 = Activation('relu')(btn_1)
X_2 = Conv2D(32,(3,3), padding='same')(act_1)
btn_2 = BatchNormalization()(X_2)
act_2 = Activation('relu')(btn_2)
X_3 = Conv2D(64,(3,3), padding='same')(act_2)
btn_3 = BatchNormalization()(X_3)
act_3 = Activation('relu')(btn_3)
X_4 = Conv2D(64,(3,3), padding='same')(X_1)
btn_4 = BatchNormalization()(X_4)
act_4 = Activation('relu')(btn_4)
C_1 = concatenate([act_3, act_4])
X_5 = Conv2D(64,(3,3))(C_1)
btn_5 = BatchNormalization()(X_5)
act_5 = Activation('relu')(btn_5)
#M_3 = MaxPool2D((2,2))(act_5)
fltn = Flatten()(btn_5)
D_1 = Dense(20,activation='relu')(fltn)
outputs = Dense(1)(D_1)
model = Model(inputs, outputs)

# 6
inputs = Input(shape= (7, 32, 1))
X_1 = Conv2D(16,(3,3),activation='relu',padding='same')(inputs)
X_2 = Conv2D(32,(3,3),activation='relu', padding='same')(X_1)
X_3 = Conv2D(64,(3,3),activation='relu', padding='same')(X_2)
X_4 = Conv2D(64,(3,3),activation='relu', padding='same')(X_1)
C_1 = concatenate([X_3, X_4])
X_5 = Conv2D(64,(3,3),activation='relu')(C_1)
#M_3 = MaxPool2D((2,2))(act_5)
fltn = Flatten()(X_5)
D_1 = Dense(20,activation='relu')(fltn)
outputs = Dense(1)(D_1)
model = Model(inputs, outputs)

# 7
inputs = Input(shape= (7, 32, 1))
###################################
X_1_1 = Conv2D(32,(1,1),activation='relu',padding='same')(inputs)
X_1_2 = Conv2D(128,(1,1),activation='relu',padding='same')(X_1_1)
X_1_3 = Conv2D(32,(3,3),activation='relu',padding='same')(X_1_2)
###################################
X_2_1 = Conv2D(32,(1,1),activation='relu', padding='same')(X_1_3)
X_2_2 = Conv2D(128,(1,1),activation='relu', padding='same')(X_2_1)
X_2_3 = Conv2D(32,(3,3),activation='relu', padding='same')(X_2_2)
###################################
X_3_1 = Conv2D(32,(1,1),activation='relu', padding='same')(X_2_3)
X_3_2 = Conv2D(128,(1,1),activation='relu', padding='same')(X_3_1)
X_3_3 = Conv2D(32,(3,3),activation='relu', padding='same')(X_3_2)
###################################
X_4_1 = Conv2D(32,(1,1),activation='relu', padding='same')(X_1_3)
X_4_2 = Conv2D(128,(1,1),activation='relu', padding='same')(X_4_1)
X_4_3 = Conv2D(32,(3,3),activation='relu', padding='same')(X_4_2)
###################################
C_1 = concatenate([X_3_3, X_4_3])
###################################
X_5_1 = Conv2D(32,(1,1),activation='relu')(C_1)
X_5_2 = Conv2D(128,(1,1),activation='relu')(X_5_1)
X_5_3 = Conv2D(32,(3,3),activation='relu')(X_5_2)
###################################
#M_3 = MaxPool2D((2,2))(act_5)
fltn = Flatten()(X_5_3)
D_1 = Dense(20,activation='relu')(fltn)
outputs = Dense(1)(D_1)
model = Model(inputs, outputs)

# 8
dim = Features.shape[1:]
cnn = Sequential()
cnn.add(Conv1D(71,2, input_shape=dim, activation="relu"))
cnn.add(Flatten())
cnn.add(Dense(71, activation="relu"))
cnn.add(Dense(1))

dim

# 9
inputs = Input(shape= (7, 32, 1))
###################################
X_1_1 = Conv2D(35,(1,1),activation='relu',padding='same')(inputs)
X_1_2 = Conv2D(139,(1,1),activation='relu',padding='same')(X_1_1)
X_1_3 = Conv2D(35,(3,3),activation='relu',padding='same')(X_1_2)
###################################
X_2_1 = Conv2D(35,(1,1),activation='relu', padding='same')(X_1_3)
X_2_2 = Conv2D(139,(1,1),activation='relu', padding='same')(X_2_1)
X_2_3 = Conv2D(35,(3,3),activation='relu', padding='same')(X_2_2)
###################################
X_3_1 = Conv2D(35,(1,1),activation='relu', padding='same')(X_2_3)
X_3_2 = Conv2D(139,(1,1),activation='relu', padding='same')(X_3_1)
X_3_3 = Conv2D(35,(3,3),activation='relu', padding='same')(X_3_2)
###################################
X_4_1 = Conv2D(35,(1,1),activation='relu', padding='same')(X_1_3)
X_4_2 = Conv2D(139,(1,1),activation='relu', padding='same')(X_4_1)
X_4_3 = Conv2D(35,(3,3),activation='relu', padding='same')(X_4_2)
###################################
C_1 = concatenate([X_3_3, X_4_3])
###################################
X_5_1 = Conv2D(35,(1,1),activation='relu')(C_1)
X_5_2 = Conv2D(139,(1,1),activation='relu')(X_5_1)
X_5_3 = Conv2D(35,(3,3),activation='relu')(X_5_2)
###################################
#M_3 = MaxPool2D((2,2))(act_5)
fltn = Flatten()(X_5_3)
D_1 = Dense(90,activation='relu')(fltn)
outputs = Dense(1)(D_1)
resnet = Model(inputs, outputs)
model = resnet

# 8  & 9
combinedInput = concatenate([cnn.output, resnet.output])
x = Dense(20, activation="relu")(combinedInput)
x = Dense(1, activation="linear")(x)
model = Model(inputs=[cnn.input, resnet.input], outputs=x)

# 10
inputs = Input(shape=7)
dense = Dense(20,activation='relu')(inputs)
dense = Dense(20,activation='relu')(dense)
ol = Dense(1)(dense)
model= Model(inputs,ol)

# 11
inputs = Input(shape= (7, 32, 1))
#####################################
c1 = Conv2D(32,(3,3),activation='relu',padding='same')(inputs)
conc = concatenate([c1, inputs])
c2 = Conv2D(64,(3,3),activation='relu')(conc)
#####################################
fltn = Flatten()(c2)
D_1 = Dense(20,activation='relu')(fltn)
outputs = Dense(1)(D_1)
#####################################
model = Model(inputs, outputs)

# 12
inputs = Input(shape= (7, 32, 1))
###################################
X_2_1 = Conv2D(32,(1,1),activation='relu', padding='same')(inputs)
X_2_2 = Conv2D(128,(1,1),activation='relu', padding='same')(X_2_1)
X_2_3 = Conv2D(32,(3,3),activation='relu', padding='same')(X_2_2)
###################################
X_3_1 = Conv2D(32,(1,1),activation='relu', padding='same')(X_2_3)
X_3_2 = Conv2D(128,(1,1),activation='relu', padding='same')(X_3_1)
X_3_3 = Conv2D(32,(3,3),activation='relu', padding='same')(X_3_2)
###################################
C_1 = concatenate([inputs, X_3_3])
###################################
X_5_1 = Conv2D(32,(1,1),activation='relu')(C_1)
X_5_2 = Conv2D(128,(1,1),activation='relu')(X_5_1)
X_5_3 = Conv2D(32,(3,3),activation='relu')(X_5_2)
###################################
#M_3 = MaxPool2D((2,2))(act_5)
fltn = Flatten()(X_5_3)
D_1 = Dense(90,activation='relu')(fltn)
outputs = Dense(1)(D_1)
resnet = Model(inputs, outputs)
model = resnet

# 8  & 12
combinedInput = concatenate([cnn.output, resnet.output])
x = Dense(20, activation="relu")(combinedInput)
x = Dense(1, activation="linear")(x)
model = Model(inputs=[cnn.input, resnet.input], outputs=x)

model.summary()

lr = 0.0002719628410285431
radam = RectifiedAdam(learning_rate=lr)
ranger = Lookahead(radam, sync_period=6, slow_step_size=0.5)
model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=lr),metrics=['mse','mae'])

model = lm.ModelWrapper(tf.keras.models.clone_model(model))
model.compile(
    optimizer=tf.keras.optimizers.SGD(learning_rate=1),
    loss=lm.MeanSquaredError())

hist = model.fit(xtr_img,ytr,
                 epochs=500,validation_split=0,verbose=1,
                 callbacks = [ES(monitor='val_loss', patience=2000000,
                                 restore_best_weights=True)])

#tr+ts+bw
hist = model.fit(feature,target,
                 epochs=100,validation_split=0,verbose=1,
                 callbacks = [ES(monitor='val_loss', patience=2000000,
                                 restore_best_weights=True)])

#tr+ts+bw
hist = model.fit([Features,feature],target,
                 epochs=100,validation_split=0,verbose=1,
                 callbacks = [ES(monitor='val_loss', patience=2000000,
                                 restore_best_weights=True)])

hist = model.fit([xtr_axi,xtr_img],ytr,
                 epochs=100,validation_split=0.3,batch_size=8,verbose=1,
                 callbacks = [ES(monitor='val_loss', patience=20,
                                 restore_best_weights=True)])

shape = feature[0].shape
r2_ts = []
r2_bw = []
pred_ts = []
pred_bw = []
hist_list = []
with tqdm(total=len(list(range(1,11))), desc="Progress", bar_format="{l_bar}{bar} [ time left: {remaining} ]") as pbar:
    for i in range(1,11):
        xtr_img,xts_img,xtr_axi,xts_axi,ytr,yts = tts(feature,features,target,train_size=0.7,random_state=i,shuffle=True)
        hist = model.fit(xtr_img,ytr,
                     epochs=10,validation_data=(x_bw,y_bw),verbose=0,callbacks = [ES(monitor='val_loss', patience=2000000,
                                 restore_best_weights=True)])
        hist_list.append(hist)
        pred_bw.append(model.predict(x_bw))
        pred_ts.append(model.predict(xts_img))
        r2_ts.append(R2(pred_ts[-1],yts.reshape(-1,1)))
        r2_bw.append(R2(pred_bw[-1],y_bw.reshape(-1,1)))
        print('ts:',r2_ts[-1])
        print('bw:',r2_bw[-1])
        pbar.update(1)

loss = hist.history['loss']
#val_loss = hist.history['val_loss']
plt.plot(loss,label='Train')
#plt.plot(val_loss,label='Validation')
plt.legend()
plt.xlabel('EPCH')
plt.ylabel('loss')

# on test set
yts_pred = model.predict([xts_axi,xts_img])
r2_ts = R2(yts_pred,yts.reshape(-1,1))
print('R2= ',r2_ts)
mse_ts = MSE(yts,yts_pred)
rmse_ts = mse_ts**0.5
print('MSE= ',mse_ts)
print('RMSE= ',rmse_ts)
plt.figure()
plt.plot(yts,yts_pred,'.')
plt.xlabel('True')
plt.ylabel('Predicted')
plt.figure()
plt.plot(yts,label='True')
plt.plot(yts_pred,'.',label='Predicted')
plt.legend()
plt.ylabel('Value')

# on train set
ytr_pred = model.predict([xtr_axi,xtr_img])
r2_tr = R2(ytr.reshape(-1,1),ytr_pred)
print('R2= ',r2_tr)
mse_tr = MSE(ytr,ytr_pred)
rmse_tr = mse_tr**0.5
print('MSE= ',mse_tr)
print('RMSE= ',rmse_tr)
plt.figure()
plt.plot(ytr,ytr_pred,'.')
plt.xlabel('True')
plt.ylabel('Predicted')
plt.figure()
plt.plot(ytr,label='True')
plt.plot(ytr_pred,'.',label='Predicted')
plt.legend()
plt.ylabel('Value')

"""**blind well data**"""

df_bw = pd.read_excel("D:/hassan sharifi/milad's project/img_b/data_bw.xlsx")
orig_df_bw = df_bw.copy()
df_bw

target_bw = df_bw.pop('log(NMR_PERM)').values
index_bw = df_bw.pop('index')
features_bw = df_bw
features_bw

Features_bw = features_bw.values.reshape(features_bw.values.shape[0],features_bw.values.shape[1],1)
target_bw = target_bw.reshape(-1,1)

bin_list = []
fig_list = []
for i in features_bw.values:
    bin_num,fig = float_to_bin(i,32)
    bin_list.append(bin_num)
    fig_list.append(fig)
x_bw = np.array(bin_list)
x_bw = np.array([i.reshape(i.shape[0],i.shape[1],1) for i in x_bw])
y_bw = target_bw
orig_df_bw['feature binary string'] = [i  for i in x_bw]
del target_bw
del bin_list
print('No. of Samples:',len(x_bw))
print('Sample Shape:',x_bw[0].shape)
print('features shape:',x_bw.shape)
print('target shape:',y_bw.shape)
orig_df_bw

ybw_pred = model.predict([Features_bw,x_bw])
r2_tr = R2(y_bw.reshape(-1,1),ybw_pred)
print('R2= ',r2_tr)
mse_tr = MSE(y_bw,ybw_pred)
rmse_tr = mse_tr**0.5
print('MSE= ',mse_tr)
print('RMSE= ',rmse_tr)
plt.figure()
plt.plot(y_bw,ybw_pred,'.')
plt.xlabel('True')
plt.ylabel('Predicted')
plt.figure()
plt.plot(y_bw,label='True')
plt.plot(ybw_pred,'.',label='Predicted')
plt.legend()
plt.ylabel('Value')

mdic = {'t':y_bw}
savemat("matlab_matrix_b_true_target_MCNN.mat",mdic)

mdic = {'y':ybw_pred}
savemat("matlab_matrix_b_pred_target_MCNN.mat",mdic)

#%% Creat Cost Function to be optimized
def model_tun (params):
    global shape
    global x_bw
    global y_bw
    no_of_nor = int(round(params[0]))
    act = int(round(params[1]))
    if act==0:
        act='sigmoid'
    elif act==1:
        act='relu'
    no_dense = int(round(params[2]))
    lr = params[3]
    bt_size = int(round(params[4]))
    #pait = int(round(params[5]))
    ############## model creating ##############
    inputs = Input(shape= (7, 32, 1))
    ###################################
    X_1_1 = Conv2D(int(round(no_of_nor/4)),(1,1),activation=act,padding='same')(inputs)
    X_1_2 = Conv2D(no_of_nor,(1,1),activation=act,padding='same')(X_1_1)
    X_1_3 = Conv2D(int(round(no_of_nor/4)),(3,3),activation=act,padding='same')(X_1_2)
    ###################################
    X_2_1 = Conv2D(int(round(no_of_nor/4)),(1,1),activation=act, padding='same')(X_1_3)
    X_2_2 = Conv2D(no_of_nor,(1,1),activation=act, padding='same')(X_2_1)
    X_2_3 = Conv2D(int(round(no_of_nor/4)),(3,3),activation=act, padding='same')(X_2_2)
    ###################################
    X_3_1 = Conv2D(int(round(no_of_nor/4)),(1,1),activation=act, padding='same')(X_2_3)
    X_3_2 = Conv2D(no_of_nor,(1,1),activation=act, padding='same')(X_3_1)
    X_3_3 = Conv2D(int(round(no_of_nor/4)),(3,3),activation=act, padding='same')(X_3_2)
    ###################################
    X_4_1 = Conv2D(int(round(no_of_nor/4)),(1,1),activation=act, padding='same')(X_1_3)
    X_4_2 = Conv2D(no_of_nor,(1,1),activation=act, padding='same')(X_4_1)
    X_4_3 = Conv2D(int(round(no_of_nor/4)),(3,3),activation=act, padding='same')(X_4_2)
    ###################################
    C_1 = concatenate([X_3_3, X_4_3])
    ###################################
    X_5_1 = Conv2D(int(round(no_of_nor/4)),(1,1),activation=act)(C_1)
    X_5_2 = Conv2D(no_of_nor,(1,1),activation=act)(X_5_1)
    X_5_3 = Conv2D(int(round(no_of_nor/4)),(3,3),activation=act)(X_5_2)
    ###################################
    #M_3 = MaxPool2D((2,2))(act_5)
    fltn = Flatten()(X_5_3)
    D_1 = Dense(no_dense,activation=act)(fltn)
    outputs = Dense(1)(D_1)
    model = Model(inputs, outputs)
    ###################### Model compile ########################
    model.compile(loss='mean_squared_error',optimizer=Adam(lr),metrics=['mse','mae'])
    ####################### Model fit #########################
    hist = model.fit(x_bw,y_bw,
             epochs=50,validation_split=0.3,batch_size=bt_size,verbose=0,
             callbacks = [ES(monitor='val_loss',
                             restore_best_weights=True)])
    ##########################################################
    pred = model.predict(x_bw)
    mse = MSE(y_bw.reshape(-1,1),pred.reshape(-1,1))
    return mse
#%% setting optimizaer parameters
low_bond = [16,0,10,1e-6,4]
high_bond = [256,1,100,0.01,128]
max_iter = 50
num_particles = 50
dim = 5
#%% Optimizing
no_of_nor,act,no_dense,lr,bt_size,pait = tlbo(model_tun, max_iter, num_particles, dim, low_bond, high_bond,
                     verbose=True)