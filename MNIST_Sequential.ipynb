{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4mgm_Lfygy7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# flatten the features from 28*28 pixel to 784 wide vector\n",
        "x_train = np.reshape(x_train, (-1, 784)).astype('float32')\n",
        "x_test = np.reshape(x_test, (-1, 784)).astype('float32')\n",
        "\n",
        "# one-hot encode the targets\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "data_slice = 1000\n",
        "x_train = x_train[:data_slice,:]\n",
        "y_train = y_train[:data_slice,:]\n",
        "x_test = x_test[:data_slice,:]\n",
        "y_test = y_test[:data_slice,:]"
      ],
      "metadata": {
        "id": "Z4hcnk2Gyqj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "i5FA4MJexqNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_dim=784))\n",
        "model.add(layers.Dense(128, activation='relu', input_dim=64))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=128))\n",
        "model.add(layers.Dense(512, activation='relu', input_dim=256))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(256, activation='relu', input_dim=512))\n",
        "model.add(layers.Dense(128, activation='relu', input_dim=256))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(64, activation='relu', input_dim=128))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Fx_Jsw9Ey2Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss = ['binary_crossentropy'], metrics=['acc'])"
      ],
      "metadata": {
        "id": "TKD9mP3U2DHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Results = model.fit(x_train, y_train, validation_split=0.2, batch_size=64, epochs=20)"
      ],
      "metadata": {
        "id": "v5EvPrWM1lxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(Results.history['loss'])\n",
        "plt.plot(Results.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(Results.history['acc'])\n",
        "plt.plot(Results.history['val_acc'])\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('Acc')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BlmH9YgzCPON"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}