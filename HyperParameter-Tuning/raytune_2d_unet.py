# -*- coding: utf-8 -*-
"""RayTune_2D_UNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/157U5BEB2HU6sXc2zKL-8FWyCiTOao8Oh
"""

from google.colab import drive
drive.mount('/content/gdrive')

# 1. Import Required Modules

import os
import glob
import keras
import random
import numpy as np
import tensorflow as tf
from keras.layers import *
import keras.backend as k
from keras.models import *
from keras.optimizers import *
import matplotlib.pyplot as plt
from skimage.transform import resize
from skimage.io import imread, imshow, imsave, imread_collection
from keras.losses import categorical_crossentropy
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping
import argparse
import os
from filelock import FileLock
!pip install 'ray[tune]'
import ray
from ray import air, tune
from ray.tune.schedulers import AsyncHyperBandScheduler
from ray.tune.integration.keras import TuneReportCallback

# 3. Initialize Images and Mask Size

IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 512, 512, 1

import glob
import cv2

Train_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob("gdrive/My Drive/Parker_Sand/Image_512x512/*.png"))]
Train_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob("gdrive/My Drive/Parker_Sand/Label_512x512/*.png"))]

Train_Input = np.array(Train_Input)
Train_Mask = np.array(Train_Mask)

Train_Mask = cv2.normalize(Train_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)

Validation_Input = Train_Input[400:421]
Train_Input = Train_Input[:100]
Validation_Mask = Train_Mask[400:421]
Train_Mask = Train_Mask[:100]

def dice_loss(y_true, y_pred):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.math.sigmoid(y_pred)
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)

    return 1 - numerator / denominator

def jacard_coef(y_true, y_pred):
    y_true_f = k.flatten(y_true)
    y_pred_f = k.flatten(y_pred)
    intersection = k.sum(y_true_f * y_pred_f)
    return (intersection + 1.0) / (k.sum(y_true_f) + k.sum(y_pred_f) - intersection + 1.0)

def iou_coef(y_true, y_pred, smooth=1):
  intersection = k.sum(k.abs(y_true * y_pred), axis=[1,2])
  union = k.sum(y_true,[1,2])+k.sum(y_pred,[1,2])-intersection
  iou = k.mean((intersection + smooth) / (union + smooth), axis=0)
  return iou

# IoU calculation
def iou_score(y_true, y_pred):
  intersection = np.logical_and(y_true, y_pred)
  union = np.logical_or(y_true, y_pred)
  iou_score = np.sum(intersection) / np.sum(union)
  return iou_score

def Model_Structure(inputs) :


    n = Lambda(lambda x:x/255)(inputs)


    c1 = Conv2D(16, (3,3), activation='relu', padding='same', kernel_initializer=tf.keras.initializers.Ones())(n)
    c1 = BatchNormalization()(c1)
    c1 = Dropout(0.1)(c1)
    c1 = Conv2D(16, (3,3), activation='relu', padding='same')(c1)
    c1 = BatchNormalization()(c1)


    p1 = MaxPooling2D((2,2))(c1)


    c2 = Conv2D(32, (3,3), activation='relu', padding='same')(p1)
    c2 = BatchNormalization()(c2)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3,3), activation='relu', padding='same')(c2)
    c2 = BatchNormalization()(c2)


    p2 = MaxPooling2D((2,2))(c2)


    c3 = Conv2D(64, (3,3), activation='relu', padding='same')(p2)
    c3 = BatchNormalization()(c3)
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3,3), activation='relu', padding='same')(c3)
    c3 = BatchNormalization()(c3)


    p3 = MaxPooling2D((2,2))(c3)


    c4 = Conv2D(128, (3,3), activation='relu', padding='same')(p3)
    c4 = BatchNormalization()(c4)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3,3), activation='relu', padding='same')(c4)
    c4 = BatchNormalization()(c4)


    p4 = MaxPooling2D((2,2))(c4)


    c5 = Conv2D(256, (3,3), activation='elu', padding='same')(p4)
    c5 = BatchNormalization()(c5)
    c5 = Dropout(0.3)(c5)
    c5 = Conv2D(256, (3,3), activation='relu', padding='same')(c5)
    c5 = BatchNormalization()(c5)


    u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)
    u6 = concatenate([u6, c4])


    c6 = Conv2D(128, (3,3), activation='relu', padding='same')(u6)
    c6 = BatchNormalization()(c6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3,3), activation='relu', padding='same')(c6)
    c6 = BatchNormalization()(c6)


    u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)
    u7 = concatenate([u7, c3])


    c7 = Conv2D(64, (3,3), activation='relu', padding='same')(u7)
    c7 = BatchNormalization()(c7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3,3), activation='relu', padding='same')(c7)
    c7 = BatchNormalization()(c7)


    u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)
    u8 = concatenate([u8, c2])


    c8 = Conv2D(32, (3,3), activation='relu', padding='same')(u8)
    c8 = BatchNormalization()(c8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv2D(32, (3,3), activation='relu', padding='same')(c8)
    c8 = BatchNormalization()(c8)


    u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)
    u9 = concatenate([u9, c1], axis = 3)


    c9 = Conv2D(16, (3,3), activation='relu', padding='same')(u9)
    c9 = BatchNormalization()(c9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv2D(16, (3,3), activation='relu', padding='same')(c9)
    c9 = BatchNormalization()(c9)

    outputs = Conv2D(1,(1,1), activation='sigmoid')(c9)

    return outputs

def U_Net_Segmentation(config):

    input_size = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)
    inputs = Input(input_size)
    outputs = Model_Structure(inputs)
    model = Model(inputs=ray.put([inputs]), outputs=ray.put([outputs]))
    model.compile(optimizer=tf.keras.optimizers.Adam(lr=config["lr"]), loss = ['binary_crossentropy'], metrics=[tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0])])
    model.summary()

    model = U_Net_Segmentation()

    results = model.fit(ray.put(Train_Input), ray.put(Train_Mask),
                    validation_data=(Validation_Input, Validation_Mask),
                    batch_size=1,
                    epochs=150
                    , callbacks=[earlystopper, TuneReportCallback({"mean_IoU": "IoU"})])

    return {"mean_IoU": results.io_u}

# 7. Show The Results per Epoch

class loss_history(keras.callbacks.Callback):

    def __init__ (self, x=4):
        self.x = x

    def on_epoch_begin(self, epoch, logs={}):

        imshow(np.squeeze(Train_Input[self.x]))
        plt.show()

        imshow(np.squeeze(Train_Mask[self.x]))
        plt.show()

        preds_train = self.model.predict(np.expand_dims(Train_Input[self.x], axis = 0))
        imshow(np.squeeze(preds_train[0]))
        plt.show()

Model_Path = 'gdrive/My Drive/Saved_Models/2D_U_Net/Tuning_Parker_IoU_2D_U_Net'

earlystopper = EarlyStopping(patience=4, verbose=1)
checkpointer = ModelCheckpoint(Model_Path, verbose = 1, save_best_only=True)

def tune_2D_UNet():


  sched = AsyncHyperBandScheduler(
        time_attr="training_iteration", max_t=400, grace_period=20
    )

  tuner = tune.Tuner(tune.with_resources(
            U_Net_Segmentation,
            resources={"cpu": 1, "gpu": 1}) ,
  tune_config=tune.TuneConfig(
        metric="mean_IoU",
        mode="max",
        scheduler=sched,
        num_samples=10,
        ),
  run_config=air.RunConfig(
            name="exp",
            stop={"mean_IoU": 0.99, "training_iteration": 1},
        ),
  param_space={
            "lr": tune.loguniform(1e-5, 1e-1),
        },
    )
  Results = tuner.fit()
  print("Best hyperparameters found were: ", Results.get_best_result().config)

tune_2D_UNet()