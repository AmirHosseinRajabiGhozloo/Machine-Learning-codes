{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9Nh-Xut3gAM"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffKyM-WH8jCb"
      },
      "outputs": [],
      "source": [
        "# 1. Import Required Modules\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import keras\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "import keras.backend as k\n",
        "from keras.models import *\n",
        "from keras.optimizers import *\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread, imshow, imsave, imread_collection\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcCOztyM9G_4"
      },
      "outputs": [],
      "source": [
        "# 3. Initialize Images and Mask Size\n",
        "\n",
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 512, 512, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqCg_8b_P30H"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import cv2\n",
        "\n",
        "Train_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Image_512x512/*.png\"))]\n",
        "Train_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Label_512x512/*.png\"))]\n",
        "\n",
        "Train_Input = np.array(Train_Input)\n",
        "Train_Mask = np.array(Train_Mask)\n",
        "\n",
        "Train_Mask = cv2.normalize(Train_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Input = Train_Input[:2500]\n",
        "Train_Mask = Train_Mask[:2500]"
      ],
      "metadata": {
        "id": "f_pnOTMD37T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxB0Wn5g37uz"
      },
      "outputs": [],
      "source": [
        "Train_Mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK3R_mn2aIau"
      },
      "outputs": [],
      "source": [
        "imshow(Train_Input[1300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBa3K9Z_ZQFD"
      },
      "outputs": [],
      "source": [
        "imshow(Train_Mask[1300], cmap='Greys_r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHs-oBYFW70D"
      },
      "outputs": [],
      "source": [
        "Train_Mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsyxOJveoe6i"
      },
      "outputs": [],
      "source": [
        "print('Training Input')\n",
        "imshow(Train_Input[45])\n",
        "plt.show()\n",
        "\n",
        "print('Training Mask')\n",
        "imshow(np.squeeze(Train_Mask[45]), cmap='Greys_r')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Input')\n",
        "imshow(Train_Input[45])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3HvL5Gi_nls2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Itg9xzgmep1"
      },
      "outputs": [],
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.math.sigmoid(y_pred)\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "    return 1 - numerator / denominator\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = k.flatten(y_true)\n",
        "    y_pred_f = k.flatten(y_pred)\n",
        "    intersection = k.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (k.sum(y_true_f) + k.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1):\n",
        "  intersection = k.sum(k.abs(y_true * y_pred), axis=[1,2])\n",
        "  union = k.sum(y_true,[1,2])+k.sum(y_pred,[1,2])-intersection\n",
        "  iou = k.mean((intersection+smooth) / (union+smooth), axis=0)\n",
        "  return iou\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = k.sum(k.round(k.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + k.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = k.sum(k.round(k.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = k.sum(k.round(k.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + k.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "   precision = precision_m(y_true, y_pred)\n",
        "   recall = recall_m(y_true, y_pred)\n",
        "   return 2*((precision*recall)/(precision+recall+k.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf2Vw7OBQIWy"
      },
      "outputs": [],
      "source": [
        "def U_Net_Segmentation(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "    n = Lambda(lambda x:x/255)(inputs)\n",
        "\n",
        "\n",
        "    c1 = Conv2D(32, (3,3), activation='relu', padding='same', kernel_initializer=tf.keras.initializers.Ones())(n)\n",
        "    #c1 = BatchNormalization()(c1)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(32, (3,3), activation='relu', padding='same')(c1)\n",
        "    #c1 = BatchNormalization()(c1)\n",
        "\n",
        "\n",
        "    p1 = MaxPooling2D((2,2))(c1)\n",
        "\n",
        "\n",
        "    c2 = Conv2D(64, (3,3), activation='relu', padding='same')(p1)\n",
        "    #c2 = BatchNormalization()(c2)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(64, (3,3), activation='relu', padding='same')(c2)\n",
        "    #c2 = BatchNormalization()(c2)\n",
        "\n",
        "\n",
        "    p2 = MaxPooling2D((2,2))(c2)\n",
        "\n",
        "\n",
        "    c3 = Conv2D(128, (3,3), activation='relu', padding='same')(p2)\n",
        "    #c3 = BatchNormalization()(c3)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(128, (3,3), activation='relu', padding='same')(c3)\n",
        "    #c3 = BatchNormalization()(c3)\n",
        "\n",
        "\n",
        "    p3 = MaxPooling2D((2,2))(c3)\n",
        "\n",
        "\n",
        "    c4 = Conv2D(256, (3,3), activation='relu', padding='same')(p3)\n",
        "    #c4 = BatchNormalization()(c4)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(256, (3,3), activation='relu', padding='same')(c4)\n",
        "    #c4 = BatchNormalization()(c4)\n",
        "\n",
        "\n",
        "    p4 = MaxPooling2D((2,2))(c4)\n",
        "\n",
        "\n",
        "    c5 = Conv2D(512, (3,3), activation='elu', padding='same')(p4)\n",
        "    #c5 = BatchNormalization()(c5)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(512, (3,3), activation='relu', padding='same')(c5)\n",
        "    #c5 = BatchNormalization()(c5)\n",
        "\n",
        "\n",
        "    u6 = Conv2DTranspose(256, (2,2), strides=(2,2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "\n",
        "\n",
        "    c6 = Conv2D(256, (3,3), activation='relu', padding='same')(u6)\n",
        "    #c6 = BatchNormalization()(c6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(256, (3,3), activation='relu', padding='same')(c6)\n",
        "    #c6 = BatchNormalization()(c6)\n",
        "\n",
        "\n",
        "    u7 = Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "\n",
        "\n",
        "    c7 = Conv2D(128, (3,3), activation='relu', padding='same')(u7)\n",
        "    #c7 = BatchNormalization()(c7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(128, (3,3), activation='relu', padding='same')(c7)\n",
        "    #c7 = BatchNormalization()(c7)\n",
        "\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "\n",
        "\n",
        "    c8 = Conv2D(64, (3,3), activation='relu', padding='same')(u8)\n",
        "    #c8 = BatchNormalization()(c8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(64, (3,3), activation='relu', padding='same')(c8)\n",
        "    #c8 = BatchNormalization()(c8)\n",
        "\n",
        "\n",
        "    u9 = Conv2DTranspose(32, (2,2), strides=(2,2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis = 3)\n",
        "\n",
        "\n",
        "    c9 = Conv2D(32, (3,3), activation='relu', padding='same')(u9)\n",
        "    #c9 = BatchNormalization()(c9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(32, (3,3), activation='relu', padding='same')(c9)\n",
        "    #c9 = BatchNormalization()(c9)\n",
        "\n",
        "    outputs = Conv2D(1,(1,1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss = ['binary_crossentropy'], metrics=[tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0, 1]), tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0]), tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1]), f1_m ,precision_m , recall_m, 'accuracy', jacard_coef])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MVnx7a3o--v"
      },
      "outputs": [],
      "source": [
        "imshow(Train_Input[15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ANTKWShIaVT"
      },
      "outputs": [],
      "source": [
        "model = U_Net_Segmentation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ibLiwARIh-a"
      },
      "outputs": [],
      "source": [
        "# 7. Show The Results per Epoch\n",
        "\n",
        "class loss_history(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__ (self, x=4):\n",
        "        self.x = x\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "\n",
        "        imshow(np.squeeze(Train_Input[self.x]))\n",
        "        plt.show()\n",
        "\n",
        "        imshow(np.squeeze(Train_Mask[self.x]), cmap='Greys_r')\n",
        "        plt.show()\n",
        "\n",
        "        preds_train = self.model.predict(np.expand_dims(Train_Input[self.x], axis = 0))\n",
        "        imshow(np.squeeze(preds_train[0]), cmap='Greys_r')\n",
        "        plt.show()\n",
        "\n",
        "Model_Path = 'gdrive/My Drive/Saved_Models/2D_U_Net/10Parker_IoU_F1_JC_ACC_Modified_U_Net_BCE_001'\n",
        "\n",
        "earlystopper = EarlyStopping(patience=7, verbose=1)\n",
        "checkpointer = ModelCheckpoint(Model_Path, verbose = 1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewtu61GCier-"
      },
      "outputs": [],
      "source": [
        "Validation_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Validation_Dataset/Image_512x512/*.png\"))]\n",
        "Validation_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Validation_Dataset/Label_512x512/*.png\"))]\n",
        "\n",
        "Validation_Input = np.array(Validation_Input)\n",
        "Validation_Mask = np.array(Validation_Mask)\n",
        "\n",
        "Validation_Mask = cv2.normalize(Validation_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVXxLotOjZBp"
      },
      "outputs": [],
      "source": [
        "Validation_Input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55Ds3p5rJTm0"
      },
      "outputs": [],
      "source": [
        "# 8. Train U_NET Model using Training Samples\n",
        "\n",
        "results = model.fit(Train_Input, Train_Mask,\n",
        "                    validation_split = 0.2,\n",
        "                    batch_size=10,\n",
        "                    epochs=150\n",
        "                    , callbacks=[earlystopper, checkpointer, loss_history()])\n",
        "\n",
        "#results = model.fit(Train_Input, Train_Mask,\n",
        "#                    validation_data=(Validation_Input, Validation_Mask),\n",
        "#                   batch_size=10,\n",
        "#                    epochs=150\n",
        "#                    , callbacks=[earlystopper, checkpointer, loss_history()])\n",
        "\n",
        "#earlystopper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nr_zHnkwJFp1"
      },
      "outputs": [],
      "source": [
        "preds_train = model.predict(Train_Input, batch_size=10)\n",
        "preds_train_t = preds_train.astype(np.uint8)\n",
        "#preds_test = model.predict(Test_Inputs, verbose=1)\n",
        "#preds_test_t = (preds_test>0.5).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9RJjlXiJGiC"
      },
      "outputs": [],
      "source": [
        "# 10. Show Final Results (Segmented Images)\n",
        "\n",
        "ix = random.randint(0, len(Train_Input)-1)\n",
        "\n",
        "print(ix)\n",
        "\n",
        "print('Train_Image')\n",
        "imshow(Train_Input[ix])\n",
        "plt.show()\n",
        "\n",
        "print('Train_Mask')\n",
        "imshow(np.squeeze(Train_Mask[ix]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Segmented_Image')\n",
        "imshow(np.squeeze(preds_train[ix]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD1k-obVJOQq"
      },
      "outputs": [],
      "source": [
        "# 11. Show Loss and ACC Plots\n",
        "\n",
        "\n",
        "# 11.1. Summarize History for Loss\n",
        "\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u'])\n",
        "plt.plot(results.history['val_io_u'])\n",
        "plt.title('iou_coef')\n",
        "plt.ylabel('IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u_1'])\n",
        "plt.plot(results.history['val_io_u_1'])\n",
        "plt.title('iou_coef')\n",
        "plt.ylabel('IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for IOU\n",
        "\n",
        "plt.plot(results.history['io_u_2'])\n",
        "plt.plot(results.history['val_io_u_2'])\n",
        "plt.title('iou_coef')\n",
        "plt.ylabel('IOU')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for Precision\n",
        "\n",
        "plt.plot(results.history['precision_m'])\n",
        "plt.plot(results.history['val_precision_m'])\n",
        "plt.title('Precision')\n",
        "plt.ylabel('Prec')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for Recall\n",
        "\n",
        "plt.plot(results.history['recall_m'])\n",
        "plt.plot(results.history['val_recall_m'])\n",
        "plt.title('Recal')\n",
        "plt.ylabel('Recl')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for F1_Score\n",
        "\n",
        "plt.plot(results.history['f1_m'])\n",
        "plt.plot(results.history['val_f1_m'])\n",
        "plt.title('F1 Score')\n",
        "plt.ylabel('F1')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for Jaccard Coefficient\n",
        "\n",
        "plt.plot(results.history['jacard_coef'])\n",
        "plt.plot(results.history['val_jacard_coef'])\n",
        "plt.title('Jaccard Coef')\n",
        "plt.ylabel('JC')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "# 11.1. Summarize History for Accuracy\n",
        "\n",
        "plt.plot(results.history['accuracy'])\n",
        "plt.plot(results.history['val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('ACC')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['Training','Validation'], loc = 'upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR1tt-Qy6qkh"
      },
      "outputs": [],
      "source": [
        "Test_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand_Texas/Test_Image_Berea_512/*.png\"))]\n",
        "Test_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Berea_Sand_Texas/Test_Mask_Berea_512/*.png\"))]\n",
        "\n",
        "Test_Input = np.array(Test_Input)\n",
        "Test_Mask = np.array(Test_Mask)\n",
        "\n",
        "Test_Mask = cv2.normalize(Test_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3LP4_1I64WS"
      },
      "outputs": [],
      "source": [
        "preds_test = model.predict(Test_Input, verbose=1)\n",
        "preds_test_t = preds_test.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usp8u2Gh7TcX"
      },
      "outputs": [],
      "source": [
        "# 10. Show Final Results (Segmented Images)\n",
        "\n",
        "ix = random.randint(0, len(Train_Input)-1)\n",
        "\n",
        "print(ix)\n",
        "\n",
        "print('Train_Image')\n",
        "imshow(Train_Input[ix])\n",
        "plt.show()\n",
        "\n",
        "print('Train_Mask')\n",
        "imshow(np.squeeze(Train_Mask[ix]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Segmented_Image')\n",
        "imshow(np.squeeze(preds_train[ix]))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "iix = random.randint(0, len(Test_Input)-1)\n",
        "\n",
        "print(ix)\n",
        "\n",
        "print('Test_Image')\n",
        "imshow(Test_Input[iix])\n",
        "plt.show()\n",
        "\n",
        "print('Test_Mask')\n",
        "imshow(np.squeeze(Test_Mask[iix]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Segmented_Image')\n",
        "imshow(np.squeeze(preds_test[iix]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK09qkbVnxDs"
      },
      "outputs": [],
      "source": [
        "preds_test_t = (preds_test>0.5).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2YUk6OXn8zi"
      },
      "outputs": [],
      "source": [
        "imshow(np.squeeze(preds_test_t[215]), cmap='Greys_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIpC8AERoOO_"
      },
      "outputs": [],
      "source": [
        "imshow(np.squeeze(Test_Mask[215]), cmap='Greys_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef-Wip51msIf"
      },
      "outputs": [],
      "source": [
        "Diff_Image = cv2.subtract(preds_test_t[215], Test_Mask[215])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27Dm5OqvnMgr"
      },
      "outputs": [],
      "source": [
        "print('Difference Image')\n",
        "imshow(np.squeeze(Diff_Image), cmap='Greys')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q9GjSBEpAnl"
      },
      "outputs": [],
      "source": [
        "intersection = np.logical_and(Test_Mask[215], preds_test_t[215])\n",
        "union = np.logical_or(Test_Mask[215], preds_test_t[215])\n",
        "iou_score = np.sum(intersection) / np.sum(union)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6Jra2Y_ngq2"
      },
      "outputs": [],
      "source": [
        "iou_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1S8fRaLKuFx"
      },
      "outputs": [],
      "source": [
        "Test_Input = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Buff_Berea_Sand/Image_512x512/*.png\"))]\n",
        "Test_Mask = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in sorted(glob.glob(\"gdrive/My Drive/Buff_Berea_Sand/Label_512x512/*.png\"))]\n",
        "\n",
        "Test_Input = np.array(Test_Input)\n",
        "Test_Mask = np.array(Test_Mask)\n",
        "\n",
        "Test_Mask = cv2.normalize(Test_Mask, None, alpha=1,beta=0, norm_type=cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XsCwdJULGeu"
      },
      "outputs": [],
      "source": [
        "preds_test = model.predict(Test_Input, verbose=1)\n",
        "preds_test_t = (preds_test>0.5).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "639wO_piLTcS"
      },
      "outputs": [],
      "source": [
        "iix = random.randint(0, len(Test_Input)-1)\n",
        "\n",
        "print(ix)\n",
        "\n",
        "print('Test_Image')\n",
        "imshow(Test_Input[iix])\n",
        "plt.show()\n",
        "\n",
        "print('Test_Mask')\n",
        "imshow(np.squeeze(Test_Mask[iix]), cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "print('Segmented_Image')\n",
        "imshow(np.squeeze(preds_test[iix]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwjNW4iqLc0E"
      },
      "outputs": [],
      "source": [
        "Diff_Image = cv2.subtract(Test_Mask[215], preds_test_t[215])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN4LzRJkLWIy"
      },
      "outputs": [],
      "source": [
        "print('Difference Image')\n",
        "imshow(np.squeeze(Diff_Image), cmap='Greys')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}